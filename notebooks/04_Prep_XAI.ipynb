{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the proposed model and define input pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "model_file = \"/models/model-proposed.h5\" # 50 neurons + 10 batch + softsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1234)\n",
    "\n",
    "clean_file   = \"/data/alexa-32k.txt\"\n",
    "malware_file = \"/data/dga-32k.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean and malware datasets\n",
    "with open(clean_file) as f:\n",
    "    clean_domains = f.read().splitlines()\n",
    "clean_domains.append(67*\"x\")\n",
    "\n",
    "with open(malware_file) as f:\n",
    "    malware_domains = f.read().splitlines()\n",
    "malware_domains.append(67*\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "charset = list(\"abcdefghijklmnopqrstuvwxyz0123456789.-\")\n",
    "dictionary = dict(zip(charset, range(len(charset))))\n",
    "reverse_dictionary = dict(zip(range(len(charset)), charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Domain Name to Vector\n",
    "def domain_to_vector(domain, dictionary):\n",
    "    res = []\n",
    "    for c in list(domain):\n",
    "        v = [float(0)] * len(dictionary)\n",
    "        v[dictionary[c]] = 1.0\n",
    "        res.append(v)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Domain List to DataSet format\n",
    "def domainlist_to_dataset(domainlist, result, dictionary):\n",
    "    x = [ domain_to_vector(v, dictionary) for v in domainlist ]\n",
    "    y = [ [result] for y in range(len(x))]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Domain Lists and Merge them\n",
    "x_clean_noarray, y_clean_noarray = domainlist_to_dataset(clean_domains, 0, dictionary)\n",
    "x_malware_noarray, y_malware_noarray = domainlist_to_dataset(malware_domains, 1, dictionary)\n",
    "x_noarray = x_clean_noarray[:-1] + x_malware_noarray\n",
    "y_noarray = y_clean_noarray[:-1] + y_malware_noarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding zeros & Convert to Array\n",
    "novalue = [float(0)] * len(dictionary)\n",
    "x_noarray_pad = pad_sequences(x_noarray, dtype=float, value=novalue, padding='post')\n",
    "x_sorted = numpy.array(x_noarray_pad, dtype=float)[:-1]\n",
    "y_sorted = numpy.array(y_noarray, dtype=float)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize dataset\n",
    "x_discard, x, y_discard, y = train_test_split(x_sorted, y_sorted, test_size=0.9, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get malware samples in a separate dataset\n",
    "x_malware_noarray_pad = pad_sequences(x_malware_noarray, dtype=float, value=novalue, padding='post')\n",
    "x_malware = numpy.array(x_malware_noarray_pad, dtype=float)[:-1]\n",
    "y_malware = numpy.array(y_malware_noarray, dtype=float)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clean samples in a separate dataset\n",
    "x_clean_noarray_pad = pad_sequences(x_clean_noarray, dtype=float, value=novalue, padding='post')\n",
    "x_clean = numpy.array(x_clean_noarray_pad, dtype=float)[:-1]\n",
    "y_clean = numpy.array(y_clean_noarray, dtype=float)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                17800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 17,851\n",
      "Trainable params: 17,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM Model\n",
    "model = load_model(model_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare False Positive and False Negative subsets to be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict malware samples\n",
    "score_malware = numpy.asarray(model.predict(x_malware))\n",
    "pred_malware = numpy.where(score_malware >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict clean samples\n",
    "score_clean = numpy.asarray(model.predict(x_clean))\n",
    "pred_clean = numpy.where(score_clean >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nosegrain.net', 'onlletgodftxsels.ru', 'dzrecwimln.com',\n",
       "       'blaspsacerpotest.com', 'cdpsad.com', 'earnestinelongstaff.net',\n",
       "       'facenine.net', 'chiefdinner.net', 'tosxxoa.com',\n",
       "       'persitretinere.com'], dtype='<U67')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtan false negatives (from malware)\n",
    "false_negative_index = numpy.where(pred_malware == 0)[0]\n",
    "numpy.random.seed(1234)\n",
    "false_negative_index_sample = numpy.random.choice(false_negative_index, 10)\n",
    "false_negative_domains = numpy.take(malware_domains, false_negative_index_sample)\n",
    "x_false_negative_domains = numpy.take(x_malware, false_negative_index_sample, axis=0)\n",
    "\n",
    "false_negative_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['doubleclick.net', 'slideshare.net', 'slickdeals.net',\n",
       "       'adplxmd.com', 'secureserver.net', 'themeforest.net',\n",
       "       'trackingclick.net', 'daikynguyenvn.com', 'prjcq.com',\n",
       "       'bookmyshow.com'], dtype='<U67')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtan false positives (from clean)\n",
    "false_positive_index = numpy.where(pred_clean == 1)[0]\n",
    "false_positive_index_sample = false_positive_index[0:10]\n",
    "false_positive_domains = numpy.take(clean_domains, false_positive_index_sample)\n",
    "x_false_positive_domains = numpy.take(x_clean, false_positive_index_sample, axis=0)\n",
    "\n",
    "false_positive_domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"pipeline\" object from the model, so we can use text explainers (they require a string as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class OneHotEncoding(TransformerMixin):\n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def fit(self, texts, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i].replace(' ', '').lower()\n",
    "        \n",
    "        x.append(\"x\"*67)\n",
    "        \n",
    "        x_seq, y_seq = domainlist_to_dataset(x, 0, dictionary)\n",
    "        return x_seq\n",
    "        \n",
    "encoding = OneHotEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padder(TransformerMixin):\n",
    "\n",
    "    def __init__(self, maxlen=500):\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        #x_noarray_padded = pad_sequences(x, dtype=float, value=novalue, padding='post', maxlen=self.maxlen)\n",
    "        x_noarray_padded = pad_sequences(x, dtype=float, value=novalue, padding='post')[:-1]\n",
    "        x_padded = numpy.array(x_noarray_padded, dtype=float)\n",
    "        y_sorted = numpy.array(y, dtype=float)\n",
    "        return x_padded\n",
    "\n",
    "padder = Padder(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "max_features = len(charset) + 1\n",
    "\n",
    "# Use Keras Scikit-learn wrapper to instantiate a LSTM with all methods\n",
    "# required by Scikit-learn for the last step of a Pipeline\n",
    "def build_model():\n",
    "    return model\n",
    "\n",
    "sklearn_lstm = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "sklearn_lstm.model = build_model()\n",
    "\n",
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(encoding, padder, sklearn_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
